name: Build Custom Backends

on:
  push:
    branches:
      - master
      - main
    paths:
      - 'backend/python/kokoro/**'
      - 'backend/python/vibevoice/**'
      - 'backend/backend.proto'
      - '.github/workflows/build-backends.yml'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io

jobs:
  build-kokoro:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Kokoro backend (CUDA 12)
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile.python
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ github.repository_owner }}/localai-backends:latest-gpu-nvidia-cuda-12-kokoro
            ${{ env.REGISTRY }}/${{ github.repository_owner }}/localai-backends:cuda12-kokoro
          build-args: |
            BACKEND=kokoro
            BUILD_TYPE=cublas
            CUDA_MAJOR_VERSION=12
            BASE_IMAGE=nvidia/cuda:12.4.0-devel-ubuntu22.04
          cache-from: type=gha
          cache-to: type=gha,mode=max

  build-vibevoice:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push VibeVoice backend (CUDA 12)
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile.python
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ github.repository_owner }}/localai-backends:latest-gpu-nvidia-cuda-12-vibevoice
            ${{ env.REGISTRY }}/${{ github.repository_owner }}/localai-backends:cuda12-vibevoice
          build-args: |
            BACKEND=vibevoice
            BUILD_TYPE=cublas
            CUDA_MAJOR_VERSION=12
            BASE_IMAGE=nvidia/cuda:12.4.0-devel-ubuntu22.04
          cache-from: type=gha
          cache-to: type=gha,mode=max
